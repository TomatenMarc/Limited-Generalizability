{"cells":[{"cell_type":"markdown","metadata":{"id":"iWrT-13Aan5h"},"source":["# Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15250,"status":"ok","timestamp":1743362632634,"user":{"displayName":"Marc Feger","userId":"05668673963966344466"},"user_tz":-120},"id":"RrkgiW86am3X","outputId":"d4994e10-5cbf-410a-8bc1-1f3d39ddf268"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Feger/am-limited-generalizability\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/Feger/am-limited-generalizability"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47989,"status":"ok","timestamp":1743362680627,"user":{"displayName":"Marc Feger","userId":"05668673963966344466"},"user_tz":-120},"id":"k74HyQfMxdyu","outputId":"ec3166af-9cd1-462a-95ee-92c1572f8b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting simpletransformers==0.70.1\n","  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.47.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (4.67.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (2024.11.6)\n","Requirement already satisfied: transformers\u003e=4.31.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (4.50.0)\n","Collecting datasets (from simpletransformers==0.70.1)\n","  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (1.14.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (1.6.1)\n","Collecting seqeval (from simpletransformers==0.70.1)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (2.18.0)\n","Collecting tensorboardx (from simpletransformers==0.70.1)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (2.2.2)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (0.21.1)\n","Requirement already satisfied: wandb\u003e=0.10.32 in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (0.19.8)\n","Collecting streamlit (from simpletransformers==0.70.1)\n","  Downloading streamlit-1.44.0-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from simpletransformers==0.70.1) (0.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers\u003e=4.31.0-\u003esimpletransformers==0.70.1) (3.18.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers\u003e=4.31.0-\u003esimpletransformers==0.70.1) (0.29.3)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers\u003e=4.31.0-\u003esimpletransformers==0.70.1) (24.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers\u003e=4.31.0-\u003esimpletransformers==0.70.1) (6.0.2)\n","Requirement already satisfied: safetensors\u003e=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers\u003e=4.31.0-\u003esimpletransformers==0.70.1) (0.5.3)\n","Requirement already satisfied: click!=8.0.0,\u003e=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (8.1.8)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (4.3.7)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,\u003c6,\u003e=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (5.29.4)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (5.9.5)\n","Requirement already satisfied: pydantic\u003c3,\u003e=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (2.10.6)\n","Requirement already satisfied: sentry-sdk\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (2.24.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (1.3.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (75.1.0)\n","Requirement already satisfied: typing-extensions\u003c5,\u003e=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003esimpletransformers==0.70.1) (3.4.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003esimpletransformers==0.70.1) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003esimpletransformers==0.70.1) (2.3.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003esimpletransformers==0.70.1) (2025.1.31)\n","Requirement already satisfied: pyarrow\u003e=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets-\u003esimpletransformers==0.70.1) (18.1.0)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets-\u003esimpletransformers==0.70.1)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting xxhash (from datasets-\u003esimpletransformers==0.70.1)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess\u003c0.70.17 (from datasets-\u003esimpletransformers==0.70.1)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec\u003c=2024.12.0,\u003e=2023.1.0 (from fsspec[http]\u003c=2024.12.0,\u003e=2023.1.0-\u003edatasets-\u003esimpletransformers==0.70.1)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets-\u003esimpletransformers==0.70.1) (3.11.14)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003esimpletransformers==0.70.1) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003esimpletransformers==0.70.1) (2025.1)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003esimpletransformers==0.70.1) (2025.1)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn-\u003esimpletransformers==0.70.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn-\u003esimpletransformers==0.70.1) (3.6.0)\n","Requirement already satisfied: altair\u003c6,\u003e=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (5.5.0)\n","Requirement already satisfied: blinker\u003c2,\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (1.9.0)\n","Requirement already satisfied: cachetools\u003c6,\u003e=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (5.5.2)\n","Requirement already satisfied: pillow\u003c12,\u003e=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (11.1.0)\n","Requirement already satisfied: tenacity\u003c10,\u003e=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (9.0.0)\n","Requirement already satisfied: toml\u003c2,\u003e=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (0.10.2)\n","Collecting watchdog\u003c7,\u003e=2.1.5 (from streamlit-\u003esimpletransformers==0.70.1)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydeck\u003c1,\u003e=0.8.0b4 (from streamlit-\u003esimpletransformers==0.70.1)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado\u003c7,\u003e=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit-\u003esimpletransformers==0.70.1) (6.4.2)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (1.71.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (3.7)\n","Requirement already satisfied: six\u003e1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard-\u003esimpletransformers==0.70.1) (3.1.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (3.1.6)\n","Requirement already satisfied: jsonschema\u003e=3.0 in /usr/local/lib/python3.11/dist-packages (from altair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (4.23.0)\n","Requirement already satisfied: narwhals\u003e=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (1.31.0)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (1.3.2)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (1.5.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (6.2.0)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (0.3.0)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets-\u003esimpletransformers==0.70.1) (1.18.3)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,\u003e=1.0.0-\u003ewandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (4.0.12)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c3,\u003e=2.6-\u003ewandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c3,\u003e=2.6-\u003ewandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (2.27.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard-\u003esimpletransformers==0.70.1) (3.0.2)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython!=3.1.29,\u003e=1.0.0-\u003ewandb\u003e=0.10.32-\u003esimpletransformers==0.70.1) (5.0.2)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (2024.10.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (0.36.2)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6,\u003e=4.0-\u003estreamlit-\u003esimpletransformers==0.70.1) (0.23.1)\n","Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit-1.44.0-py3-none-any.whl (9.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=739b94207d1ab3fa1d0835fcc6bb3ba9ef3e424bbe34ae989642a5319664d33c\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n","Successfully built seqeval\n","Installing collected packages: xxhash, watchdog, tensorboardx, fsspec, dill, pydeck, multiprocess, seqeval, datasets, streamlit, simpletransformers\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 pydeck-0.9.1 seqeval-1.2.2 simpletransformers-0.70.1 streamlit-1.44.0 tensorboardx-2.6.2.2 watchdog-6.0.0 xxhash-3.5.0\n","Collecting transformers==4.41.1\n","  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (3.18.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (0.29.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (24.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (2.32.3)\n","Collecting tokenizers\u003c0.20,\u003e=0.19 (from transformers==4.41.1)\n","  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (0.5.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1) (4.67.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.23.0-\u003etransformers==4.41.1) (2024.12.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.23.0-\u003etransformers==4.41.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers==4.41.1) (3.4.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers==4.41.1) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers==4.41.1) (2.3.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers==4.41.1) (2025.1.31)\n","Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.50.0\n","    Uninstalling transformers-4.50.0:\n","      Successfully uninstalled transformers-4.50.0\n","Successfully installed tokenizers-0.19.1 transformers-4.41.1\n","Collecting emoji==2.4.0\n","  Downloading emoji-2.4.0.tar.gz (353 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/353.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.4.0-py2.py3-none-any.whl size=350808 sha256=c6309db5d199c7817108bf52bf5572ab9acd049f62728bc237fa7000a6937ebf\n","  Stored in directory: /root/.cache/pip/wheels/8c/bf/17/02e400a37d0292f1a44ec18e58cfb29b2db6eb86e9c0c3a03f\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.4.0\n","Collecting en-core-web-lg==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["! pip install simpletransformers==0.70.1\n","! pip install transformers==4.41.1\n","! pip install emoji==2.4.0\n","! python -m spacy download en_core_web_lg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3P0T8Bqa3kp"},"outputs":[],"source":["import gc\n","import os\n","import time\n","import math\n","import torch\n","import spacy\n","import string\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from itertools import product\n","from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n","from sklearn.model_selection import BaseCrossValidator\n","from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, make_scorer\n","from sklearn.model_selection import GridSearchCV, KFold\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.exceptions import ConvergenceWarning\n","from sklearn.dummy import DummyClassifier\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n","from sklearn.tree import DecisionTreeClassifier\n","from simpletransformers.classification import ClassificationModel\n","from IPython.display import clear_output\n","from tqdm.notebook import tqdm\n","from transformers import logging as transformers_logging\n","from google.colab import runtime\n","\n","# Set logging level for transformers to ERROR\n","transformers_logging.set_verbosity_error()\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n","warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n","\n","# Generate stop words\n","nlp = spacy.load(\"en_core_web_lg\", disable=['ner', 'parser', 'textcat', 'senter'])\n","stop_words = nlp.Defaults.stop_words\n","\n","# Set several random seed for reproducibility and classification\n","random_seed = 201221\n","\n","# Define a mapping of class names to labels\n","class2label = {\"Argument\": 1, \"No-Argument\": 0}\n","label2class = {1: \"Argument\", 0: \"No-Argument\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VxhEL3qavtm"},"outputs":[],"source":["df_sample = pd.read_csv('./data/sample_374318.csv')\n","df_sample[\"label\"] = df_sample[\"label\"].replace(class2label)\n","assert not df_sample.isna().any().any()"]},{"cell_type":"markdown","metadata":{"id":"n84Iho0pcwK6"},"source":["# Methodology"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjMWaZ_Rq8MX"},"outputs":[],"source":["class TransformerModel(BaseEstimator):\n","    def __init__(self,\n","                 model_type=None,\n","                 model_name=None,\n","                 learning_rate=None,\n","                 num_train_epochs=None,\n","                 batch_size=None,\n","                 random_state=None):\n","        # Initialize parameters\n","        self.model_type = model_type\n","        self.model_name = model_name\n","        self.learning_rate = learning_rate\n","        self.num_train_epochs = num_train_epochs\n","        self.batch_size = batch_size\n","        self.random_state = random_state\n","        self.model = None  # Placeholder for the model\n","        self.args = None  # Placeholder for model arguments\n","\n","    def show_information(self):\n","        # Display model configuration information\n","        print(\"Model:\", self.model_name)\n","        print(\"Learning Rate:\", self.model.args.learning_rate)\n","        print(\"Number of Train Epochs:\", self.model.args.num_train_epochs)\n","        print(\"Train Batch Size:\", self.model.args.train_batch_size)\n","        print(\"Manual Seed:\", self.model.args.manual_seed)\n","\n","    def check_parameters(self):\n","        # Verify that all parameters are correctly set\n","        for key, value in self.args.items():\n","            model_value = getattr(self.model.args, key, None)\n","            # Ensure all parameters are initialized and match the expected values\n","            assert value is not None, f\"Parameter {key} is None (default) in the argument dict\"\n","            assert model_value is not None, f\"Parameter {key} is None (default) in the model\"\n","            assert model_value == value, f\"Parameter {key} is {model_value} but expected {value}\"\n","\n","    def fit(self, X, y):\n","        # Set up model arguments based on current parameters\n","        self.args = {\n","            'eval_batch_size': self.batch_size,\n","            'learning_rate': self.learning_rate,\n","            'manual_seed': self.random_state,\n","            'no_cache': True,\n","            'no_save': True,\n","            'num_train_epochs': self.num_train_epochs,\n","            'overwrite_output_dir': True,\n","            'save_eval_checkpoints': False,\n","            'save_model_every_epoch': False,\n","            'silent': False,\n","            'train_batch_size': self.batch_size,\n","            'use_multiprocessing': False,\n","            'use_multiprocessing_for_evaluation': False\n","        }\n","        # Create a DataFrame from the input data\n","        train_data = pd.DataFrame(list(zip(X, y)), columns=['text', 'labels'])\n","        # Initialize the model with the specified type and name, and the arguments\n","        self.model = ClassificationModel(self.model_type, self.model_name, args=self.args, use_cuda=torch.cuda.is_available())\n","        # Verify that all parameters are correctly set\n","        self.check_parameters()\n","        # Train the model and clean up memory\n","        self.model.train_model(train_data)\n","        gc.collect()\n","        return self\n","\n","    def predict(self, X):\n","        # Make predictions on the provided data\n","        predictions, _ = self.model.predict(X)\n","        return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qxt-if7akC-"},"outputs":[],"source":["class Fold(BaseCrossValidator):\n","    def __init__(self, df, source, target):\n","        # Initialize with a DataFrame, source dataset, and target dataset\n","        self.df = df\n","        self.source = source\n","        self.target = target\n","\n","    def split(self, X, y=None, groups=None):\n","        # Find indices for the training set from the source dataset\n","        train_idx = self.df[(self.df[\"dataset\"].isin(self.source)) \u0026 (self.df[\"split\"] == \"train\")].index.values\n","        # Find indices for the dev set from the target dataset\n","        dev_idx = self.df[(self.df[\"dataset\"].isin(self.target)) \u0026 (self.df[\"split\"] == \"dev\")].index.values\n","        # Yield the training and dev indices\n","        yield train_idx, dev_idx\n","\n","    def get_n_splits(self, X=None, y=None, groups=None):\n","        # Return the number of splits, which is 1 in this case\n","        return 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH-YTa7xPA-C"},"outputs":[],"source":["class FeatureSelector(BaseEstimator, TransformerMixin):\n","    # Use when features are in a list of lists\n","    def __init__(self, key):\n","        self.key = key  # Key to select feature(s)\n","\n","    def fit(self, X, y=None):\n","        return self  # No fitting needed\n","\n","    def transform(self, X):\n","        # Select features based on key\n","        return [x[self.key] for x in X]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwHY73muAeJF"},"outputs":[],"source":["def select_features(df, features):\n","    # Use when features are in columns of a dataframe\n","    # Check if features is a single string, if so, return values as a flat list\n","    if isinstance(features, str):\n","        return df[features].tolist()\n","    # Otherwise, return values as a list of lists\n","    return df[features].values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZuwLj-gM--A"},"outputs":[],"source":["def create_non_existing_folders(path):\n","    # Get the directory name from the given path\n","    directory = os.path.dirname(path)\n","    # Check if the directory does not exist\n","    if not os.path.exists(directory):\n","        # Create the directory and any necessary intermediate directories\n","        os.makedirs(directory)\n","    # Return the original path\n","    return path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdD3fPvLXuXZ"},"outputs":[],"source":["def run_experiment(df, model, model_type, model_name, cv, params, file_name, features):\n","    # Reset indices for consistent access\n","    df.reset_index(drop=True, inplace=True)\n","    # Create the output path and check if file already exists\n","    path = create_non_existing_folders(f\"./output/classification/{file_name}.npy\")\n","    print(path)\n","    if os.path.exists(path):\n","        print(f\"File already exists: {path}\")\n","        return\n","    # Define parameter grid for TransformerModelWrapper\n","    if isinstance(model, TransformerModel):\n","        params.update({\n","            'model_type': [model_type],\n","            'model_name': [model_name]\n","        })\n","    # Initialize and fit GridSearchCV\n","    start_time = int(time.perf_counter())\n","    clf = GridSearchCV(model, params, cv=cv, scoring='f1_macro', refit=False, verbose=3)\n","    clf.fit(select_features(df, features), df['label'].tolist())\n","    # Set and verify best parameters\n","    best_estimator = model.set_params(**clf.best_params_)\n","    for k, v in clf.best_params_.items():\n","        assert v == best_estimator.get_params()[k], f\"Parameter {k} was not set correctly.\"\n","    # Split data into training, dev, and test sets\n","    df_train = df[(df[\"dataset\"].isin(cv.source)) \u0026 (df[\"split\"] == \"train\")]\n","    df_dev = df[(df[\"dataset\"].isin(cv.target)) \u0026 (df[\"split\"] == \"dev\")]\n","    df_test = df[(df[\"dataset\"].isin(cv.target)) \u0026 (df[\"split\"] == \"test\")]\n","    # Select the features of the train, dev and test\n","    train_features = select_features(df_train, features)\n","    dev_features = select_features(df_dev, features)\n","    test_features = select_features(df_test, features)\n","    # Fit best estimator on training data\n","    best_estimator.fit(train_features, df_train[\"label\"].tolist())\n","    # Generate predictions and store them as variables\n","    df_dev[\"prediction\"] = best_estimator.predict(dev_features)\n","    df_test[\"prediction\"] = best_estimator.predict(test_features)\n","    # Generate classification reports\n","    target_names = [v for k, v in sorted(label2class.items(), key=lambda item: item[0])]\n","    report_dev = classification_report(df_dev[\"label\"], df_dev[\"prediction\"], output_dict=True, target_names=target_names)\n","    report_test = classification_report(df_test[\"label\"], df_test[\"prediction\"], output_dict=True, target_names=target_names)\n","    # Check for equivalence of grid search results and refit, but use tolerance as floating point numbers are compared\n","    assert math.isclose(clf.best_score_, report_dev[\"macro avg\"][\"f1-score\"], rel_tol=1e-8, abs_tol=1e-8)\n","    # Check the type of best_estimator and retrieve the random_state accordingly\n","    rnd_state = None\n","    if isinstance(best_estimator, Pipeline):\n","        last_step_name, last_step = best_estimator.steps[-1]\n","        rnd_state = last_step.random_state\n","    elif isinstance(best_estimator, TransformerModel):\n","        rnd_state = best_estimator.model.args.manual_seed\n","    else:\n","        rnd_state = best_estimator.random_state\n","    # Write the results for each datasize\n","    df_dev[\"prediction\"] = df_dev[\"prediction\"].replace(label2class)\n","    df_test[\"prediction\"] = df_test[\"prediction\"].replace(label2class)\n","    scores_params = [{\n","        \"model\": model_name,\n","        \"random_state\": rnd_state,\n","        \"source\": cv.source,\n","        \"target\": cv.target,\n","        \"size\": df.shape[0],\n","        \"best_params\": clf.best_params_,\n","        \"dev_report\": report_dev,\n","        \"test_report\": report_test,\n","        \"time_sec\": int(time.perf_counter()) - start_time,\n","        \"df_dev\": df_dev[[\"dataset_id\", \"prediction\"]],\n","        \"df_test\": df_test[[\"dataset_id\", \"prediction\"]]\n","    }]\n","    np.save(path, scores_params, allow_pickle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ON054NaMXuXa"},"outputs":[],"source":["def calculate_progress(executed, total, start_time):\n","    # Calculate the progress percentage and round it to 2 decimal places\n","    progress = round(100 * (executed / total), 2)\n","    # Calculate the total time elapsed since start_time\n","    total_time = int(time.perf_counter()) - start_time\n","    # Convert total_time to hours, minutes, and seconds\n","    hours, remainder = divmod(total_time, 3600)\n","    minutes, seconds = divmod(remainder, 60)\n","    # Return the formatted progress and uptime string\n","    return f\"Finished: {executed}/{total} ({progress}%)\\nUptime {hours}h:{minutes}m:{seconds}s\\nCurrent:\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMPJZJJNSHON"},"outputs":[],"source":["def experiment(df, params, model, model_type, model_name, folder, experiment_type, features):\n","    assert experiment_type in [\"train-on-one-test-on-another\", \"leave-one-out\", \"to-what-transformers-pay-attention\"], \"Experiment type is not valid\"\n","    # Ensure the model is properly initialized if it's an instance of TransformerModel\n","    if isinstance(model, TransformerModel):\n","        _ = ClassificationModel(model_type, model_name, use_cuda=torch.cuda.is_available())\n","        clear_output(wait=True)\n","    # Generate a list of experiment configurations based on experiment_type\n","    unique_datasets = df[\"dataset\"].unique()\n","    if experiment_type == \"train-on-one-test-on-another\" or experiment_type == \"to-what-transformers-pay-attention\":\n","        experiments = list(product(unique_datasets, repeat=2))\n","    elif experiment_type == \"leave-one-out\":\n","        experiments = [(unique_datasets[unique_datasets != out].tolist(), out) for out in unique_datasets]\n","    assert experiments, \"Experiment must be defined\"\n","    total_experiments = len(experiments)  # Total number of experiments\n","    start_time = int(time.perf_counter())  # Record the start time for progress tracking\n","    # Iterate through each experiment configuration\n","    for executed, (source, target) in enumerate(experiments):\n","        # Generate file appendix\n","        base_path = f\"{experiment_type}/{folder}/\"\n","        path = f\"{base_path}{target.lower()}\" if experiment_type == \"leave-one-out\" else f\"{base_path}{source.lower()}-{target.lower()}\"\n","        # Ensure source and target are lists\n","        source = source if isinstance(source, list) else [source]\n","        target = target if isinstance(target, list) else [target]\n","        # Print the current progress\n","        print(calculate_progress(executed, total_experiments, start_time))\n","        # Filter the DataFrame to include only the relevant datasets for the current experiment\n","        df_ = df[df[\"dataset\"].isin(source + target)]\n","        assert sorted(df_[\"dataset\"].unique()) == sorted(set(source + target))\n","        # Initialize a custom cross-validator with the filtered DataFrame and current datasets\n","        cv = Fold(df=df_, source=source, target=target)\n","        # Run the experiment with the current configuration\n","        run_experiment(\n","            df=df_,\n","            model=model,\n","            model_type=model_type,\n","            model_name=model_name,\n","            cv=cv,\n","            params=params,\n","            file_name=path,\n","            features=features\n","        )\n","        # Clear the output and collect garbage to manage memory usage\n","        clear_output(wait=True)\n","        gc.collect()\n","    print(\"Finished\")"]},{"cell_type":"markdown","metadata":{"id":"IY8YDXSPiFLZ"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNdgU6LwwQO1"},"outputs":[],"source":["# Parameters for random prediction (random seed later changed)\n","random_params = {}\n","random_model = DummyClassifier(strategy=\"uniform\", random_state=random_seed)\n","\n","# Predefined POS tags\n","OPEN_CLASS_TAGS = ['ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB']\n","CLOSED_CLASS_TAGS = ['ADP', 'AUX', 'CCONJ', 'DET', 'NUM', 'PART', 'PRON', 'SCONJ']\n","OTHER_TAGS = ['PUNCT', 'SYM', 'X']\n","predefined_pos_tags = OPEN_CLASS_TAGS + CLOSED_CLASS_TAGS + OTHER_TAGS\n","\n","# Combined parameters for decision tree and pipeline\n","dt_combined_params = {\n","    'kbst__k': [1, 2, 3, 4, 5, 6, 7, 'all'],\n","    'clf__max_depth': [1, 2, 3, 4, 5, None],\n","    'clf__criterion': [\"gini\", \"entropy\", \"log_loss\"],\n","}\n","\n","# Create the combined pipeline with merged parameters\n","dt_combined_model = Pipeline([\n","    ('union', FeatureUnion([\n","        ('pos', Pipeline([\n","            ('selector', FeatureSelector(key=0)),\n","            ('cvect', CountVectorizer(vocabulary=predefined_pos_tags, lowercase=False)) #Counts POS tags in the string representation of pos_tags using the predefined vocabulary.\n","        ])),\n","        ('num', FeatureSelector(key=slice(1, None)))\n","    ])),\n","    ('vtrsh', VarianceThreshold()),  # Remove constant pos features\n","    ('kbst', SelectKBest(f_classif)),  # Select k-best features\n","    ('clf', DecisionTreeClassifier(random_state=random_seed))\n","])\n","\n","# Parameters for transformer models, based on recommendations for text classification (GLUE) in the BERT/RoBERTa paper (random seed later changed)\n","transformer_params = {\n","    'learning_rate': [2e-5, 3e-5, 4e-5, 5e-5],\n","    'num_train_epochs': [3],\n","    'batch_size': [32]\n","}\n","transformer_model = TransformerModel(random_state=random_seed)"]},{"cell_type":"markdown","metadata":{"id":"P-iOP2BJrbJy"},"source":["# Classification"]},{"cell_type":"markdown","metadata":{"id":"ZgvpEn0Wa6b2"},"source":["## Train on one, test on another"]},{"cell_type":"markdown","metadata":{"id":"P9xT1Oeyr-NO"},"source":["### Dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrJNn3dtrzGm"},"outputs":[],"source":["experiment(df_sample, random_params, random_model, \"Random\", \"Random\", folder=\"sample_374318/Random\", experiment_type=\"train-on-one-test-on-another\", features=\"sentence\")"]},{"cell_type":"markdown","metadata":{"id":"lQxWmVMzr_x3"},"source":["### Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L93Mioqpr2fe"},"outputs":[],"source":["experiment(df_sample, dt_combined_params, dt_combined_model, \"DTree\", \"DTree\", folder=f\"sample_374318/DTree\", experiment_type=\"train-on-one-test-on-another\", features=df_sample.iloc[:, 7:].columns)"]},{"cell_type":"markdown","metadata":{"id":"ar3866P3sDzW"},"source":["### Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLmEnQg5sQX3"},"outputs":[],"source":["experiment(df_sample, transformer_params, transformer_model, \"bertweet\", \"TomatenMarc/WRAPresentations\", folder=\"sample_374318/Wrap\", experiment_type=\"train-on-one-test-on-another\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"bert\", \"bert-base-uncased\", folder=\"sample_374318/Bert\", experiment_type=\"train-on-one-test-on-another\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"roberta\", \"roberta-base\", folder=\"sample_374318/Roberta\", experiment_type=\"train-on-one-test-on-another\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"distilbert\", \"distilbert-base-uncased\", folder=\"sample_374318/Distilbert\", experiment_type=\"train-on-one-test-on-another\", features=\"sentence\")"]},{"cell_type":"markdown","metadata":{"id":"giCVBhv5UECe"},"source":["## To what transformers pay attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClemCf3tTdkV"},"outputs":[],"source":["df_sample[\"content_words\"] = df_sample.sentence.apply(lambda row: \" \".join([token for token in row.split() if token not in stop_words and token not in string.punctuation]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DMHS2cUtUrWC"},"outputs":[],"source":["experiment(df_sample, transformer_params, transformer_model, \"bertweet\", \"TomatenMarc/WRAPresentations\", folder=\"sample_374318/Wrap\", experiment_type=\"to-what-transformers-pay-attention\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"bert\", \"bert-base-uncased\", folder=\"sample_374318/Bert\", experiment_type=\"to-what-transformers-pay-attention\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"roberta\", \"roberta-base\", folder=\"sample_374318/Roberta\", experiment_type=\"to-what-transformers-pay-attention\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"distilbert\", \"distilbert-base-uncased\", folder=\"sample_374318/Distilbert\", experiment_type=\"to-what-transformers-pay-attention\", features=\"content_words\")"]},{"cell_type":"markdown","metadata":{"id":"Elatf3Gs5O3a"},"source":["## Leave one out"]},{"cell_type":"markdown","metadata":{"id":"3VQIHD-hsKg8"},"source":["### Dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"K46HrtgwsMq4"},"outputs":[],"source":["experiment(df_sample, random_params, random_model, \"Random\", \"Random\", folder=\"sample_374318/Random\", experiment_type=\"leave-one-out\", features=\"sentence\")"]},{"cell_type":"markdown","metadata":{"id":"-2PYq63isI2F"},"source":["### Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IotLSJ3xsQWU"},"outputs":[],"source":["experiment(df_sample, dt_combined_params, dt_combined_model, \"DTree\", \"DTree\", folder=f\"sample_374318/DTree\", experiment_type=\"leave-one-out\", features=df_sample.iloc[:, 7:].columns)"]},{"cell_type":"markdown","metadata":{"id":"1c51-Jy4sHdu"},"source":["### Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"a4U4UdOI5RTB"},"outputs":[],"source":["experiment(df_sample, transformer_params, transformer_model, \"bertweet\", \"TomatenMarc/WRAPresentations\", folder=\"sample_374318/Wrap\", experiment_type=\"leave-one-out\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"bert\", \"bert-base-uncased\", folder=\"sample_374318/Bert\", experiment_type=\"leave-one-out\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"roberta\", \"roberta-base\", folder=\"sample_374318/Roberta\", experiment_type=\"leave-one-out\", features=\"sentence\")\n","experiment(df_sample, transformer_params, transformer_model, \"distilbert\", \"distilbert-base-uncased\", folder=\"sample_374318/Distilbert\", experiment_type=\"leave-one-out\", features=\"sentence\")"]},{"cell_type":"markdown","metadata":{"id":"RNEcWpm1K85r"},"source":["#### Manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgqOa7QnK7q7"},"outputs":[],"source":["df_sample[\"content_words\"] = df_sample.sentence.apply(lambda row: \" \".join([token for token in row.split() if token not in stop_words and token not in string.punctuation]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":177},"id":"NKL6WRnHLGUn"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23f3d8a795704a54bcf560efecb8e7c2","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/3 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bce93537e3d247d9ae2af1f68c482735","version_major":2,"version_minor":0},"text/plain":["Running Epoch 1 of 3:   0%|          | 0/510 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a7632efbdad4ac29e3c2cb9653a5328","version_major":2,"version_minor":0},"text/plain":["Running Epoch 2 of 3:   0%|          | 0/510 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4d13f4520e948aeb7e6a780417e2cab","version_major":2,"version_minor":0},"text/plain":["Running Epoch 3 of 3:   0%|          | 0/510 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1aad3e625164be88de7a4d45bc57754","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/11 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[CV 1/1] END batch_size=32, learning_rate=2e-05, model_name=distilbert-base-uncased, model_type=distilbert, num_train_epochs=3;, score=0.659 total time=  49.0s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2cf86bbebcf4b4aa552c5bf390a11d1","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/3 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e551b6a19c66440aab70f727ea8ca24d","version_major":2,"version_minor":0},"text/plain":["Running Epoch 1 of 3:   0%|          | 0/510 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"255a2843a2604dd1a50577a82cd43451","version_major":2,"version_minor":0},"text/plain":["Running Epoch 2 of 3:   0%|          | 0/510 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["experiment(df_sample, transformer_params, transformer_model, \"bertweet\", \"TomatenMarc/WRAPresentations\", folder=\"sample_374318_manipulated/Wrap\", experiment_type=\"leave-one-out\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"bert\", \"bert-base-uncased\", folder=\"sample_374318_manipulated/Bert\", experiment_type=\"leave-one-out\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"roberta\", \"roberta-base\", folder=\"sample_374318_manipulated/Roberta\", experiment_type=\"leave-one-out\", features=\"content_words\")\n","experiment(df_sample, transformer_params, transformer_model, \"distilbert\", \"distilbert-base-uncased\", folder=\"sample_374318_manipulated/Distilbert\", experiment_type=\"leave-one-out\", features=\"content_words\")"]},{"cell_type":"markdown","metadata":{"id":"RKdAvksiSOQb"},"source":["# Clean Up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DD1V5KY2yuLs"},"outputs":[],"source":["runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["iWrT-13Aan5h","n84Iho0pcwK6","IY8YDXSPiFLZ","ZgvpEn0Wa6b2","P9xT1Oeyr-NO","lQxWmVMzr_x3","ar3866P3sDzW","giCVBhv5UECe","3VQIHD-hsKg8","-2PYq63isI2F"],"gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ec86f4a09c745019c84dcc87fe7abdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c060a48a85440018b56288b2c82b3e1","placeholder":"​","style":"IPY_MODEL_f95c88e0b9a34a43ad64dcc5edd9cce1","value":"Epochs 3/3. Running Loss:    0.3162:  45%"}},"127cc0a8d7144d0a80cfb2ed782e4de7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ec86f4a09c745019c84dcc87fe7abdf","IPY_MODEL_a840e506fed14cf691fbe5647a464781","IPY_MODEL_9845d808a08c49889b8411dda5dbd67c"],"layout":"IPY_MODEL_b5008637034943e49ba1310f8852373d"}},"209a038f4c834fa2b30479972b86ec01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a61a838c2c64aaba1d9694f05a78279":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c7e52988b3c44e3906923e4b4c6a178":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_780136e44f924b7b809cd69a4f217071","placeholder":"​","style":"IPY_MODEL_8f69531054b043ca93fbc9711ab70fc0","value":" 384/510 [00:22\u0026lt;00:07, 17.52it/s]"}},"328c0e9cfcc74e6d84979040c77be4f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff382f85fda44520aefe000b9ddfe1c2","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55541edfc4cc4f808913d866d2277557","value":2}},"3ca0e79480aa4bcea06e340ece856d76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f7598f540cf4a5fa84bcb626b94579b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec31a5f249d2433480f77eaacd9fd3d3","IPY_MODEL_a1fa790dbb1d429b82d079076991dd36","IPY_MODEL_2c7e52988b3c44e3906923e4b4c6a178"],"layout":"IPY_MODEL_3ca0e79480aa4bcea06e340ece856d76"}},"55541edfc4cc4f808913d866d2277557":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c060a48a85440018b56288b2c82b3e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6505b3eff55847c8ad4d80f81b480ef2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72029ea2aeae4f2da9069b5cea4a5d97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"780136e44f924b7b809cd69a4f217071":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ab923267c9c4af3bc24e85a3516eaf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8af76baa4be34765a47f2a42c76c5537":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f69531054b043ca93fbc9711ab70fc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9845d808a08c49889b8411dda5dbd67c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9002d00c344fdf91acea148c1195b3","placeholder":"​","style":"IPY_MODEL_8ab923267c9c4af3bc24e85a3516eaf7","value":" 228/510 [00:13\u0026lt;00:16, 16.65it/s]"}},"9f9002d00c344fdf91acea148c1195b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1b976d25af646a3bcd0a99de31dc816":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1fa790dbb1d429b82d079076991dd36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcab2f5dd520484cb98258b3320f10cb","max":510,"min":0,"orientation":"horizontal","style":"IPY_MODEL_209a038f4c834fa2b30479972b86ec01","value":384}},"a840e506fed14cf691fbe5647a464781":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca22ce73921a4d4e9847e2aaff124e26","max":510,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6505b3eff55847c8ad4d80f81b480ef2","value":228}},"aef71f5c0e1145debd3d42d3e186789c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5008637034943e49ba1310f8852373d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b91602f7432b498ba8dc2ad2181ab169":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcab2f5dd520484cb98258b3320f10cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca22ce73921a4d4e9847e2aaff124e26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e1a4bea3d04cedba97f5d6db47adaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a61a838c2c64aaba1d9694f05a78279","placeholder":"​","style":"IPY_MODEL_ed8018ae69c6439794b73df63af9dafd","value":" 2/3 [00:58\u0026lt;00:29, 29.47s/it]"}},"e6502ffa643f465db61c8d05f9530b1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8af76baa4be34765a47f2a42c76c5537","placeholder":"​","style":"IPY_MODEL_a1b976d25af646a3bcd0a99de31dc816","value":"Epoch 3 of 3:  67%"}},"ec31a5f249d2433480f77eaacd9fd3d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72029ea2aeae4f2da9069b5cea4a5d97","placeholder":"​","style":"IPY_MODEL_b91602f7432b498ba8dc2ad2181ab169","value":"Epochs 1/3. Running Loss:    0.5991:  75%"}},"ed8018ae69c6439794b73df63af9dafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f95c88e0b9a34a43ad64dcc5edd9cce1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd846f892a204b29b63b89be30089fcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6502ffa643f465db61c8d05f9530b1a","IPY_MODEL_328c0e9cfcc74e6d84979040c77be4f7","IPY_MODEL_e1e1a4bea3d04cedba97f5d6db47adaf"],"layout":"IPY_MODEL_aef71f5c0e1145debd3d42d3e186789c"}},"ff382f85fda44520aefe000b9ddfe1c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}